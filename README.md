Arguita AI Inference & RAG Utils
üìÑ Descripci√≥n General
Este repositorio contiene una suite de scripts en Python y utilidades de shell dise√±adas para el despliegue y la gesti√≥n de sistemas de Inferencia de Modelos de IA y Recuperaci√≥n Aumentada por Generaci√≥n (RAG). Nuestro objetivo es proporcionar herramientas eficientes para la orquestaci√≥n de tareas as√≠ncronas y el servicio de modelos de IA en diversos entornos.

El proyecto se enfoca en:

Eficiencia: Optimizaci√≥n de la carga y ejecuci√≥n de modelos.

Escalabilidad: Uso de Celery para procesamiento as√≠ncrono y distribuido.

Automatizaci√≥n: Scripts de shell para la gesti√≥n simplificada de servicios.

üöÄ Caracter√≠sticas Destacadas
Inferencia de Modelos: Scripts base para cargar y ejecutar modelos de inteligencia artificial de manera optimizada.

Recuperaci√≥n Aumentada por Generaci√≥n (RAG): Componentes dedicados a la integraci√≥n de sistemas de recuperaci√≥n de informaci√≥n con modelos generativos para respuestas contextuales.

Servidores Gunicorn: Configuraciones robustas para la publicaci√≥n de APIs de inferencia y RAG.

Workers de Celery: Implementaci√≥n de tareas as√≠ncronas para el procesamiento en segundo plano y la escalabilidad de las operaciones.

Scripts de Monitoreo: Utilidades de shell para iniciar, detener y monitorear el estado de los servicios clave.

Bases de Datos Vectoriales: Integraci√≥n con sistemas de bases de datos vectoriales (como ChromaDB) para la gesti√≥n y b√∫squeda eficiente de embeddings.

Gesti√≥n de Modelos: Funcionalidades para la carga din√°mica y la gesti√≥n de diferentes modelos de IA.

üìÅ Estructura del Proyecto
A continuaci√≥n, se detalla la organizaci√≥n de los archivos y directorios principales dentro de este repositorio:

.
‚îú‚îÄ‚îÄ __pycache__/             # Directorio de cach√© de Python (ignorado por .gitignore)
‚îú‚îÄ‚îÄ chroma_db/               # Base de datos vectorial (ChromaDB - Ignorado por .gitignore)
‚îú‚îÄ‚îÄ env/                     # Entorno virtual de Python (Ignorado por .gitignore)
‚îú‚îÄ‚îÄ env_models/              # Otro entorno virtual (Ignorado por .gitignore)
‚îú‚îÄ‚îÄ models/                  # Directorio para almacenar modelos de IA (Ignorado por .gitignore)
‚îÇ
‚îú‚îÄ‚îÄ gunicorn.inference.py    # Configuraci√≥n de Gunicorn para el servicio de inferencia.
‚îú‚îÄ‚îÄ gunicorn.inference_models.py # Configuraci√≥n de Gunicorn para el servicio de gesti√≥n de modelos.
‚îú‚îÄ‚îÄ gunicorn.rag.py          # Configuraci√≥n de Gunicorn para el servicio RAG.
‚îÇ
‚îú‚îÄ‚îÄ inference.py             # L√≥gica principal para la ejecuci√≥n de inferencias con modelos.
‚îú‚îÄ‚îÄ inference_models.py      # L√≥gica para la carga, descarga y gesti√≥n de modelos.
‚îÇ
‚îú‚îÄ‚îÄ kill_services.sh         # Script de shell para detener todos los servicios Gunicorn y Celery.
‚îú‚îÄ‚îÄ models_celery_config.py  # Archivo de configuraci√≥n para los workers de Celery de modelos.
‚îú‚îÄ‚îÄ models_celery_worker.py  # Implementaci√≥n del worker de Celery para tareas relacionadas con modelos.
‚îÇ
‚îú‚îÄ‚îÄ monit_celery_models_worker.sh # Script de monitoreo para el worker de Celery de modelos.
‚îú‚îÄ‚îÄ monit_celery_rag_worker.sh    # Script de monitoreo para el worker de Celery de RAG.
‚îú‚îÄ‚îÄ monit_gunicorn_inference.sh   # Script de monitoreo para la instancia de Gunicorn de inferencia.
‚îú‚îÄ‚îÄ monit_gunicorn_models.sh      # Script de monitoreo para la instancia de Gunicorn de modelos.
‚îú‚îÄ‚îÄ monit_gunicorn_rag.sh         # Script de monitoreo para la instancia de Gunicorn de RAG.
‚îÇ
‚îú‚îÄ‚îÄ rag.py                   # L√≥gica principal para el sistema de Recuperaci√≥n Aumentada por Generaci√≥n (RAG).
‚îú‚îÄ‚îÄ rag_celery_config.py     # Archivo de configuraci√≥n para los workers de Celery de RAG.
‚îú‚îÄ‚îÄ rag_celery_worker.py     # Implementaci√≥n del worker de Celery para tareas relacionadas con RAG.
‚îÇ
‚îú‚îÄ‚îÄ restart_services.sh      # Script de shell para reiniciar todos los servicios.
‚îú‚îÄ‚îÄ start_services.sh        # Script de shell para iniciar todos los servicios.
‚îú‚îÄ‚îÄ suggest_monit_matching.sh # Script de shell para sugerir configuraciones de monitoreo basadas en los servicios.
‚îú‚îÄ‚îÄ test.sh                  # Script de shell para pruebas generales del entorno.
‚îú‚îÄ‚îÄ test_celery.py           # Script de Python para probar la funcionalidad de Celery.
‚îú‚îÄ‚îÄ test_ollama.py           # Script de Python para probar la integraci√≥n con Ollama (si aplica).
‚îÇ
‚îî‚îÄ‚îÄ .gitignore               # Archivo de configuraci√≥n de Git para ignorar archivos y directorios.

‚öôÔ∏è Requisitos del Sistema
Para poder ejecutar y desarrollar con estos scripts, necesitar√°s tener instalados los siguientes componentes en tu sistema:

Python 3.x (versi√≥n recomendada: 3.8 o superior)

pip (el gestor de paquetes de Python)

Git (para clonar y gestionar el repositorio)

Gunicorn (servidor WSGI para aplicaciones Python)

Celery (sistema de cola de tareas distribuidas)

Broker de Mensajes: Un broker como RabbitMQ o Redis es necesario para que Celery funcione.

[Opcional] Ollama: Si planeas utilizar los scripts de prueba o funcionalidades que interact√∫an con Ollama, aseg√∫rate de tenerlo instalado y configurado.

Instalaci√≥n de Dependencias de Python
Se recomienda encarecidamente crear y activar un entorno virtual para gestionar las dependencias de Python de forma aislada:

# 1. Crea un entorno virtual (si no existe)
python3 -m venv env

# 2. Activa el entorno virtual
source env/bin/activate

# 3. Instala las dependencias listadas en requirements.txt
pip install -r requirements.txt

Nota: Aseg√∫rate de que el archivo requirements.txt est√© actualizado con todas las bibliotecas de Python que tus scripts necesitan. Puedes generarlo ejecutando pip freeze > requirements.txt en tu entorno virtual despu√©s de instalar todas las dependencias.

üöÄ Uso
Configuraci√≥n Inicial
Clonar el Repositorio:

git clone https://github.com/alemitaritonna/arguita-ai-inference-utils.git
cd arguita-ai-inference-utils

Instalar Dependencias:
Sigue los pasos de la secci√≥n "Instalaci√≥n de Dependencias de Python" para configurar tu entorno.

Configurar Variables de Entorno:
Algunos scripts (especialmente los de Gunicorn y Celery) pueden depender de variables de entorno para configurar puertos, URLs de brokers, rutas a modelos o claves API. Aseg√∫rate de que estas variables est√©n definidas en tu entorno de ejecuci√≥n.

Si utilizas un archivo .env o similar para cargar variables de entorno, menci√≥nalo aqu√≠ y explica c√≥mo cargarlo (ej. source .env).

Ejecuci√≥n de Servicios
Los scripts de shell en la ra√≠z del proyecto facilitan la gesti√≥n de los servicios principales:

Iniciar todos los servicios (Gunicorn y Celery workers):

./start_services.sh

Reiniciar todos los servicios:

./restart_services.sh

Detener todos los servicios:

./kill_services.sh

Monitoreo de Servicios
Los scripts con prefijo monit_ est√°n dise√±ados para ser integrados con un sistema de monitoreo como monit o systemd para asegurar la alta disponibilidad de los servicios cr√≠ticos.

Si tienes configuraciones espec√≠ficas para monit o instrucciones detalladas sobre c√≥mo usar estos scripts de monitoreo, agr√©galas aqu√≠.

Uso de Scripts Espec√≠ficos
inference.py: Este script contiene la l√≥gica para cargar modelos de IA y realizar inferencias. Puedes interactuar con √©l a trav√©s de la API expuesta por Gunicorn.

Ejemplo de uso: python inference.py --model_path /ruta/a/tu/modelo (ajusta seg√∫n la implementaci√≥n).

rag.py: Implementa el sistema RAG, combinando la recuperaci√≥n de documentos con la generaci√≥n de texto.

Ejemplo de uso: python rag.py --query "Pregunta sobre el documento" (ajusta seg√∫n la implementaci√≥n).

test_celery.py: Util√≠zalo para verificar que la configuraci√≥n de Celery es correcta y que los workers est√°n procesando tareas.

Ejemplo de uso: python test_celery.py

test_ollama.py: Si est√°s usando Ollama, este script te ayudar√° a probar la conexi√≥n y las funcionalidades b√°sicas.

Ejemplo de uso: python test_ollama.py

ü§ù Contribuciones
¬°Las contribuciones son bienvenidas y muy apreciadas! Si deseas contribuir a este proyecto, por favor sigue estos pasos:

Haz un "fork" de este repositorio.

Crea una nueva rama para tu funcionalidad o correcci√≥n (git checkout -b feature/nombre-de-tu-funcionalidad o fix/correccion-de-bug).

Realiza tus cambios y commitea con un mensaje claro y descriptivo (git commit -m 'feat: A√±adir soporte para nuevo modelo X').

Sube tus cambios a tu repositorio forkeado (git push origin feature/nombre-de-tu-funcionalidad).

Abre un Pull Request desde tu rama hacia la rama main de este repositorio.

üìú Licencia
Este proyecto est√° bajo la licencia [Nombre de la Licencia, ej. MIT License]. Consulta el archivo LICENSE en la ra√≠z del repositorio para m√°s detalles sobre los t√©rminos y condiciones de uso.

üìû Contacto
Para cualquier pregunta, comentario o sugerencia, no dudes en contactarme:

GitHub: @alemitaritonna

Email (Opcional): [tu.email@ejemplo.com]
