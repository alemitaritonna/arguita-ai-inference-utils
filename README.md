# Arguita AI Inference & RAG Utils

## üìÑ Descripci√≥n General

Este repositorio contiene una suite de scripts en Python y utilidades de shell dise√±adas para el despliegue y la gesti√≥n de sistemas de Inferencia de Modelos de IA y Recuperaci√≥n Aumentada por Generaci√≥n (RAG). Nuestro objetivo es proporcionar herramientas eficientes para la orquestaci√≥n de tareas as√≠ncronas y el servicio de modelos de IA en diversos entornos.

El proyecto se enfoca en:

- **Eficiencia**: Optimizaci√≥n de la carga y ejecuci√≥n de modelos.
- **Escalabilidad**: Uso de Celery para procesamiento as√≠ncrono y distribuido.
- **Automatizaci√≥n**: Scripts de shell para la gesti√≥n simplificada de servicios.

## üöÄ Caracter√≠sticas Destacadas

- **Inferencia de Modelos**: Scripts base para cargar y ejecutar modelos de inteligencia artificial de manera optimizada.
- **Recuperaci√≥n Aumentada por Generaci√≥n (RAG)**: Componentes dedicados a la integraci√≥n de sistemas de recuperaci√≥n de informaci√≥n con modelos generativos para respuestas contextuales.
- **Servidores Gunicorn**: Configuraciones robustas para la publicaci√≥n de APIs de inferencia y RAG.
- **Workers de Celery**: Implementaci√≥n de tareas as√≠ncronas para el procesamiento en segundo plano y la escalabilidad de las operaciones.
- **Scripts de Monitoreo**: Utilidades de shell para iniciar, detener y monitorear el estado de los servicios clave.
- **Bases de Datos Vectoriales**: Integraci√≥n con sistemas de bases de datos vectoriales (como ChromaDB) para la gesti√≥n y b√∫squeda eficiente de embeddings.
- **Gesti√≥n de Modelos**: Funcionalidades para la carga din√°mica y la gesti√≥n de diferentes modelos de IA.

## üìÅ Estructura del Proyecto

```bash
.
‚îú‚îÄ‚îÄ __pycache__/             
‚îú‚îÄ‚îÄ chroma_db/               
‚îú‚îÄ‚îÄ env/                     
‚îú‚îÄ‚îÄ env_models/              
‚îú‚îÄ‚îÄ models/                  
‚îÇ
‚îú‚îÄ‚îÄ gunicorn.inference.py
‚îú‚îÄ‚îÄ gunicorn.inference_models.py
‚îú‚îÄ‚îÄ gunicorn.rag.py
‚îÇ
‚îú‚îÄ‚îÄ inference.py
‚îú‚îÄ‚îÄ inference_models.py
‚îÇ
‚îú‚îÄ‚îÄ kill_services.sh
‚îú‚îÄ‚îÄ models_celery_config.py
‚îú‚îÄ‚îÄ models_celery_worker.py
‚îÇ
‚îú‚îÄ‚îÄ monit_celery_models_worker.sh
‚îú‚îÄ‚îÄ monit_celery_rag_worker.sh
‚îú‚îÄ‚îÄ monit_gunicorn_inference.sh
‚îú‚îÄ‚îÄ monit_gunicorn_models.sh
‚îú‚îÄ‚îÄ monit_gunicorn_rag.sh
‚îÇ
‚îú‚îÄ‚îÄ rag.py
‚îú‚îÄ‚îÄ rag_celery_config.py
‚îú‚îÄ‚îÄ rag_celery_worker.py
‚îÇ
‚îú‚îÄ‚îÄ restart_services.sh
‚îú‚îÄ‚îÄ start_services.sh
‚îú‚îÄ‚îÄ suggest_monit_matching.sh
‚îú‚îÄ‚îÄ test.sh
‚îú‚îÄ‚îÄ test_celery.py
‚îú‚îÄ‚îÄ test_ollama.py
‚îÇ
‚îî‚îÄ‚îÄ .gitignore
````

## ‚öôÔ∏è Requisitos del Sistema

* Python 3.x (versi√≥n recomendada: 3.8 o superior)
* pip
* Git
* Gunicorn
* Celery
* **Broker de Mensajes**: RabbitMQ o Redis
* \[Opcional] Ollama

## üíª Instalaci√≥n de Dependencias de Python

```bash
# 1. Crea un entorno virtual (si no existe)
python3 -m venv env

# 2. Activa el entorno virtual
source env/bin/activate

# 3. Instala las dependencias
pip install -r requirements.txt
```

> Aseg√∫rate de que el archivo `requirements.txt` est√© actualizado:
>
> ```bash
> pip freeze > requirements.txt
> ```

## üöÄ Uso

### Configuraci√≥n Inicial

```bash
git clone https://github.com/alemitaritonna/arguita-ai-inference-utils.git
cd arguita-ai-inference-utils
```

Sigue los pasos de instalaci√≥n anteriores.

Si utilizas un archivo `.env`:

```bash
source .env
```

### Ejecuci√≥n de Servicios

```bash
# Iniciar todos los servicios
./start_services.sh

# Reiniciar todos los servicios
./restart_services.sh

# Detener todos los servicios
./kill_services.sh
```

### Monitoreo de Servicios

Los scripts con prefijo `monit_` est√°n pensados para integrarse con `monit` o `systemd`.

### Uso de Scripts Espec√≠ficos

* **`inference.py`**: Carga modelos de IA y realiza inferencias.

```bash
python inference.py --model_path /ruta/a/tu/modelo
```

* **`rag.py`**: Sistema RAG: recuperaci√≥n de documentos + generaci√≥n.

```bash
python rag.py --query "Pregunta sobre el documento"
```

* **`test_celery.py`**: Verifica la configuraci√≥n de Celery.

```bash
python test_celery.py
```

* **`test_ollama.py`**: Prueba la integraci√≥n con Ollama.

```bash
python test_ollama.py
```


## üìú Licencia

Este proyecto est√° bajo la licencia **\[Nombre de la Licencia, ej. MIT License]**. Revisa el archivo `LICENSE`.

## üìû Contacto

* GitHub: [alemitaritonna](https://github.com/alemitaritonna)
* Email: \[[tu.email@ejemplo.com](mailto:tu.email@ejemplo.com)]


