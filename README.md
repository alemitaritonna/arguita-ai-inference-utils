# Arguita AI Inference & RAG Utils

## ðŸ“„ DescripciÃ³n General

Este repositorio contiene una suite de scripts en Python y utilidades de shell diseÃ±adas para el despliegue y la gestiÃ³n de sistemas de Inferencia de Modelos de IA y RecuperaciÃ³n Aumentada por GeneraciÃ³n (RAG). Nuestro objetivo es proporcionar herramientas eficientes para la orquestaciÃ³n de tareas asÃ­ncronas y el servicio de modelos de IA en diversos entornos.

El proyecto se enfoca en:

- **Eficiencia**: OptimizaciÃ³n de la carga y ejecuciÃ³n de modelos.
- **Escalabilidad**: Uso de Celery para procesamiento asÃ­ncrono y distribuido.
- **AutomatizaciÃ³n**: Scripts de shell para la gestiÃ³n simplificada de servicios.

## ðŸš€ CaracterÃ­sticas Destacadas

- **Inferencia de Modelos**: Scripts base para cargar y ejecutar modelos de inteligencia artificial de manera optimizada.
- **RecuperaciÃ³n Aumentada por GeneraciÃ³n (RAG)**: Componentes dedicados a la integraciÃ³n de sistemas de recuperaciÃ³n de informaciÃ³n con modelos generativos para respuestas contextuales.
- **Servidores Gunicorn**: Configuraciones robustas para la publicaciÃ³n de APIs de inferencia y RAG.
- **Workers de Celery**: ImplementaciÃ³n de tareas asÃ­ncronas para el procesamiento en segundo plano y la escalabilidad de las operaciones.
- **Scripts de Monitoreo**: Utilidades de shell para iniciar, detener y monitorear el estado de los servicios clave.
- **Bases de Datos Vectoriales**: IntegraciÃ³n con sistemas de bases de datos vectoriales (como ChromaDB) para la gestiÃ³n y bÃºsqueda eficiente de embeddings.
- **GestiÃ³n de Modelos**: Funcionalidades para la carga dinÃ¡mica y la gestiÃ³n de diferentes modelos de IA.

## ðŸ“ Estructura del Proyecto

```bash
.
â”œâ”€â”€ __pycache__/             
â”œâ”€â”€ chroma_db/               
â”œâ”€â”€ env/                     
â”œâ”€â”€ env_models/              
â”œâ”€â”€ models/                  
â”‚
â”œâ”€â”€ gunicorn.inference.py
â”œâ”€â”€ gunicorn.inference_models.py
â”œâ”€â”€ gunicorn.rag.py
â”‚
â”œâ”€â”€ inference.py
â”œâ”€â”€ inference_models.py
â”‚
â”œâ”€â”€ kill_services.sh
â”œâ”€â”€ models_celery_config.py
â”œâ”€â”€ models_celery_worker.py
â”‚
â”œâ”€â”€ monit_celery_models_worker.sh
â”œâ”€â”€ monit_celery_rag_worker.sh
â”œâ”€â”€ monit_gunicorn_inference.sh
â”œâ”€â”€ monit_gunicorn_models.sh
â”œâ”€â”€ monit_gunicorn_rag.sh
â”‚
â”œâ”€â”€ rag.py
â”œâ”€â”€ rag_celery_config.py
â”œâ”€â”€ rag_celery_worker.py
â”‚
â”œâ”€â”€ restart_services.sh
â”œâ”€â”€ start_services.sh
â”œâ”€â”€ suggest_monit_matching.sh
â”œâ”€â”€ test.sh
â”œâ”€â”€ test_celery.py
â”œâ”€â”€ test_ollama.py
â”‚
â””â”€â”€ .gitignore
````

## âš™ï¸ Requisitos del Sistema

* Python 3.x (versiÃ³n recomendada: 3.8 o superior)
* pip
* Git
* Gunicorn
* Celery
* **Broker de Mensajes**: Redis
* \[Opcional] Ollama

## ðŸ’» InstalaciÃ³n de Dependencias de Python

```bash
# 1. Crea un entorno virtual (si no existe)
python3 -m venv env

# 2. Activa el entorno virtual
source env/bin/activate

# 3. Instala las dependencias
pip install -r requirements.txt
```

> AsegÃºrate de que el archivo `requirements.txt` estÃ© actualizado:
>
> ```bash
> pip freeze > requirements.txt
> ```

## ðŸš€ Uso

### ConfiguraciÃ³n Inicial

```bash
git clone https://github.com/alemitaritonna/arguita-ai-inference-utils.git
cd arguita-ai-inference-utils
```

### EjecuciÃ³n de Servicios

```bash
# Iniciar todos los servicios
./start_services.sh

# Reiniciar todos los servicios
./restart_services.sh

# Detener todos los servicios
./kill_services.sh
```

### Monitoreo de Servicios

Los scripts con prefijo `monit_` estÃ¡n pensados para integrarse con `monit` o `systemd`.

### Uso de Scripts EspecÃ­ficos

* **`inference.py`**: Carga modelos de IA y realiza inferencias.

```bash
python inference.py --model_path /ruta/a/tu/modelo
```

* **`rag.py`**: Sistema RAG: recuperaciÃ³n de documentos + generaciÃ³n.

```bash
python rag.py --query "Pregunta sobre el documento"
```

* **`test_celery.py`**: Verifica la configuraciÃ³n de Celery.

```bash
python test_celery.py
```

* **`test_ollama.py`**: Prueba la integraciÃ³n con Ollama.

```bash
python test_ollama.py
```


## ðŸ“œ Licencia

Este proyecto estÃ¡ bajo la licencia **\[Nombre de la Licencia, ej. MIT License]**. Revisa el archivo `LICENSE`.

## ðŸ“ž Contacto

* GitHub: [alemitaritonna](https://github.com/alemitaritonna)
* Email: \[[tu.email@ejemplo.com](mailto:tu.email@ejemplo.com)]


